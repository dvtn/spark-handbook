Mind Map generated by NB MindMap plugin   
> __version__=`1.1`,showJumps=`true`
---

# SparkCore

## Spark
> collapsed=`true`


### Spark是分布式计算框架

### Spark底层操作的是RDD

### 与MR的区别
> collapsed=`true`


#### 1\.Spark基于内存迭代处理数据，MR是基于磁盘迭代处理数据

#### 2\.Spark中有DAG有向无环图执行引擎，执行速度快

## Spark技术栈
> collapsed=`true`


### HDFS,MR,Yarn

### Hive, Storm

### SparkCore, SparkStreaming, SparkSQL, SparkMlLib

## Spark运行模式
> collapsed=`true`


### local
> collapsed=`true`


#### 用于本地IDEA,eclipse开发，多用于测试

### standalone
> collapsed=`true`


#### Spark自带的资源调度框架

#### 支持分布式搭建

#### Spark可以基于standalone集群提交任务

### yarn
> collapsed=`true`


#### Hadoop生态圈中的资源调度框架

#### Spark也支持在yarn中运行

### mesos
> collapsed=`true`


#### 资源调度框架

## Spark代码流程
> collapsed=`true`


### 1\.创建 val conf = new SparkConf\(\)\.setMaster\("\.\.\."\)\.setAppName\("\.\.\."\)

### 2\.创建 val sc = new SparkContext\(conf\)

### 3\.得到RDD: val rdd = sc\.textFile\("\.\.\."\)

### 4\.对得到的RDD使用Transformation类算子进行数据转换

### 5\.使用Action类算子触发执行

### 6\.sc\.stop\(\)

## Spark核心RDD
> collapsed=`true`


### RDD\(Resilient Distributed Dataset\):弹性分布式数据集

### 五大特性
> collapsed=`true`


#### 1\.RDD由一系列partition组成

#### 2\.算子是作用在partition上的;

#### 3\.RDD之间有依赖关系

#### 4\.分区器是作用在K,V格式的RDD上

#### 5\.partition对外提供最佳的计算位置，利于数据处理的本地化

### 问题
> collapsed=`true`


#### 1\.什么是KV格式的RDD?
> collapsed=`true`


##### RDD中的元素是一个个的tuple2

#### 2\.sc\.textFile\(\.\.\.\)
> collapsed=`true`


##### 底层调用的是MR读取HDFS的方法, 首先也会split,一个split对应一个block, 这里的split也对应一个partition

#### 3\.哪里体现了RDD的分布式？
> collapsed=`true`


##### RDD中的partition是分布在多个节点上的

#### 4\.哪里体现了RDD的弹性？
> collapsed=`true`


##### 1\.partition的个数可多可少

##### 2\.RDD之间有依赖关系

### RDD中是不存数据的，partition中也不存数据

## Spark算子
> collapsed=`true`


### Transformation\(懒执行，需要Action类算子触发\)
> collapsed=`true`


#### filter

#### map

#### flatMap

#### reduceByKey

#### sortBy

#### sortByKey

#### sample

#### join

#### leftOuterJoin

#### rightOuterJoin

#### fullOuterJoin

#### union

#### intersection

#### subtract

#### distinct
> collapsed=`true`


##### map\+reduceByKey\+map

#### cogroup

#### mapPartitions

### Action\(触发Transformation类算子执行,一个Application中有几个Action算子，就有几个job\)
> collapsed=`true`


#### count

#### foreach

#### collect

#### first
> collapsed=`true`


##### first=take\(1\)

#### take

#### foreachPartition

### 持久化算子
> collapsed=`true`


#### cache
> collapsed=`true`


##### 默认将数据存在内存中

##### cache\(\)=persist\(\)=perist\(StorageLevel\.MEMORY\_ONLY\)

#### persist
> collapsed=`true`


##### 可以动指定数据的持久化级别

##### StorageLevel
> collapsed=`true`


###### MEMORY\_ONLY

###### MEMORY\_ONLY\_SER

###### MEMORY\_AND\_DISK

###### MEMORY\_AND\_DISK\_SER

#### checkPoint
> collapsed=`true`


##### 可以将数据持久化到磁盘

##### 切断RDD间的依赖关系

##### 当lineage非常长，计算又复杂时，可以使用checkPoint对RDD进行持久化

##### 当application执行完毕后，checkPoint中的数据不会被清除

##### checkPoint执行流程
> collapsed=`true`


###### 1\.当application有action算子触发执行时，job执行完成后，会从后往前回溯

###### 2\.回溯去找哪些RDD被checkpoint做标记

###### 3\.回溯完成后，重新计算checkpoint RDD的数据，将结果写入指定的checkpoint目录中

###### 4\.切断RDD的依赖关系

###### 优化：对RDD进行checkpoint之前，最好先cache一下

#### 注意
> collapsed=`true`


##### 1\.cache和persist的最小单位是partition, 懒执行,需要action算子触发

##### 2\.对一个RDD使用cache或者persist后，可以赋值给一个变量，下次直接使用这个变量就是使用持久化的数据

##### 3\.当Application执行完毕之后，cache和persist持久化的数据会被清除

## Spark集群搭建
> collapsed=`true`


### 1\.上传解压包

### 2\.配置 \.\./conf/slaves
> collapsed=`true`


#### 配置worker节点

### 3\.配置 \.\./conf/spark\-env\.sh
> collapsed=`true`


#### SPARK\_MASTER\_IP=node1
> collapsed=`true`


##### Master节点

#### SPARK\_MASTER\_PORT=7077
> collapsed=`true`


##### 提交任务的端口

#### SPARK\_WORKER\_CORES=2
> collapsed=`true`


##### 配置worker使用的cores

#### SPARK\_WORKER\_MEMORY=3g
> collapsed=`true`


##### 配置worker节点支配内存

### 4\.将配置好的安装包发送到其它节点
> collapsed=`true`


#### scp \-r \.\./spark\.\.\.node2:\`pwd\`

### 5\.在Master节点启动集群
> collapsed=`true`


#### \.\./sbin/start\-all\.sh

### 6\.WEBUI查看集群
> collapsed=`true`


#### http://node1:8080

#### 修改端口
> collapsed=`true`


##### 1\.配置\.\./conf/spark\-env\.sh
> collapsed=`true`


###### SPARK\_MASTER\_WEBUI\_PORT=9999

##### 2\.修改Master节点中的\.\./sbin/start\-master\.sh

##### 3\.临时导入环境变量
> collapsed=`true`


###### export SPARK\_MASTER\_WEBUI\_PORT=8888

###### 删除临时环境变量
> collapsed=`true`


####### export \-n SPARK\_MASTER\_WEBUI\_PORT=8888

## Spark客户端
> collapsed=`true`


### 原封不动将安装包拷贝到一台新的节点

## SparkPi任务提交
> collapsed=`true`


### \.\./sbin/spark\-submit \-\-master spark://node1:7077 \-\-class org\.apache\.spark\.examples\.SparkPi \.\./lib/spark\-examples\.\.\.\.jar 参数

## Spark基于yarn提交任务配置
> collapsed=`true`


### 在客户端\.\./conf/spark\-env\.sh中配置
> collapsed=`true`


#### HADOOP\_CONF\_DIR=$HADOOP\_HOME/etc/hadoop

## Spark任务提交
> collapsed=`true`


### standalone
> collapsed=`true`


#### client
> collapsed=`true`


##### 1\.在客户端提交application，Driver在客户端启动

##### 2\.客户端向Master申请资源,Master返回worker节点

##### 3\.Driver向Worker节点发送task,监控task执行，回收结果

#### cluster
> collapsed=`true`


##### 1\.在客户端提交Application,首先客户端向Master申请启动Driver

##### 2\.Master随机在一台worker中启动Driver

##### 3\.Driver启动后，Driver向Master申请资源，Master返回资源

##### 4\.Driver发送task, 监控task, 回收结果

#### Driver的功能
> collapsed=`true`


##### 1\.发送task

##### 2\.监控task

##### 3\.申请资源

##### 4\.回收结果

### yarn
> collapsed=`true`


#### client
> collapsed=`true`


##### 1\.在客户端提交Application,Driver在客户端启动

##### 2\.客户端向ResourceManager申请启动ApplicationMaster

##### 3\.RM收到请求后，随机在一台NodeManager节点上启动ApplicationMaster

##### 4\.ApplicationMaster启动之后，向ResourceManager申请资源，用于启动Executor

##### 5\.ResourceManager收到请求后，返回给ApplicationMaster一批NodeManager节点

##### 6\.ApplicationMaster连接NodeManager启动Executor

##### 7\.Executor启动之后，反向注册给Driver

##### 8\.Driver发送task, 监控task, 回收结果

#### client
> collapsed=`true`


##### 1\.在客户端提交Application,首先客户端向ResourceManager申请启动ApplicationMaster

##### 2\.RM收到请求后，随机在一台NodeManager节点上启动ApplicationMaster\(Driver\)

##### 3\.ApplicationMaster启动之后，向ResourceManager申请资源，用于启动Executor

##### 4\.ResourceManager收到请求后，返回给ApplicationMaster一批NodeManager节点

##### 5\.ApplicationMaster连接NodeManager启动Executor

##### 6\.Executor启动之后，反向注册给ApplicationMaster\(Driver\)

##### 7\.ApplicationMaster\(Driver\)发送task, 监控task, 回收结果

#### ApplicationMaster作用
> collapsed=`true`


##### 1\.申请资源

##### 2\.启动Executor

##### 3\.任务调度
